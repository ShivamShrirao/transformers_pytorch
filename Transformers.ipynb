{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0f3187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c88d8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55f843f",
   "metadata": {},
   "source": [
    "$\\begin{equation*}\\Large\n",
    "Attention(Q,K,V) = softmax\\left(\\frac{QK^{T}}{\\sqrt{d_k}}\\right)V\n",
    "\\end{equation*}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d667747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def forward(self, q, k, v, mask=None): # q,k[B, N, dv, dim]\n",
    "        dim = q.size(-1)\n",
    "        scale = dim**-0.5\n",
    "        q *= scale\n",
    "        \n",
    "        attn = torch.matmul(q, k.transpose(-1,-2)).softmax(dim=-1) # [B, N, dv, dv]\n",
    "        \n",
    "        out = torch.matmul(attn, v)    # [B, N, dv, dim]\n",
    "        return out, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38d444bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "atn = Attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7a21030",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.Tensor([[10, 0, 0],\n",
    "                  [0, 10, 0],\n",
    "                  [0, 0, 10],\n",
    "                  [0, 0, 10]])[None,:][None,:]\n",
    "\n",
    "v = torch.Tensor([[1, 0],\n",
    "                  [10, 0],\n",
    "                  [100, 5],\n",
    "                  [1000, 6]])[None,:][None,:]\n",
    "\n",
    "q = torch.Tensor([[0, 10, 0]])[None,:][None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7acc43e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 1, 3]), torch.Size([1, 1, 4, 3]), torch.Size([1, 1, 4, 2]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e1b2002",
   "metadata": {},
   "outputs": [],
   "source": [
    "o, a = atn(q,k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dca57dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 1, 4]), torch.Size([1, 1, 1, 2]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c350ecba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0., 1., 0., 0.]]]]), tensor([[[[10.,  0.]]]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.round(), o.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6179b974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
